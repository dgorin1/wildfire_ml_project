{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd1dce81",
   "metadata": {},
   "source": [
    "# Read in and examine data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a995d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "\n",
    "# Read in data\n",
    "from pathlib import Path\n",
    "\n",
    "# Build the path to the data file:\n",
    "# - The notebook is in src/notebooks/\n",
    "# - \"..\" moves up one directory to src/\n",
    "# - \"data\" enters src/data/\n",
    "# - The filename points to the specific fire dataset\n",
    "data_path = Path(\"..\") / \"data\" / \"feds_western_us_2019_af_postprocessed.parquet\"\n",
    "\n",
    "# Read the Parquet file as a GeoDataFrame\n",
    "df = gpd.read_parquet(data_path)\n",
    "\n",
    "# Print columns, CRS, and the first few rows to inspect the dataset\n",
    "print(\"COLUMNS:\", df.columns)\n",
    "print(\"CRS:\", df.crs)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ba3efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the longest duration fire and subset it for initial pipeline development\n",
    "\n",
    "# Reset the index so 't' and 'fireID' become columns rather than index levels\n",
    "df_flat = df.reset_index()\n",
    "\n",
    "# Identify the row with the maximum fire area ('farea')\n",
    "max_area = df_flat.farea.idxmax()\n",
    "\n",
    "# Extract the fireID associated with that maximum-area fire\n",
    "max_fire_id = df_flat.loc[max_area, \"fireID\"]\n",
    "\n",
    "# Subset the full DataFrame to include only rows belonging to this \"hero\" fire\n",
    "hero_fire = df_flat.loc[df_flat.fireID == max_fire_id, :]\n",
    "\n",
    "# Display the first 5 rows of this fire's time series\n",
    "hero_fire.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3255a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from geocube.api.core import make_geocube\n",
    "\n",
    "# Rename the geometry column to \"geometry\" so geocube knows which column\n",
    "# contains spatial features for rasterization\n",
    "hero_fire = hero_fire.rename_geometry(\"geometry\")\n",
    "\n",
    "# Use geocube to rasterize the hero_fire GeoDataFrame into a gridded dataset:\n",
    "# - vector_data: the GeoDataFrame to rasterize\n",
    "# - resolution: y and x pixel size in CRS units (here 500 m pixels; negative y for \"north-up\")\n",
    "# - measurements: which attribute(s) to rasterize into the grid (here, fireID)\n",
    "# - output_crs: target coordinate reference system for the raster\n",
    "# - group_by: create a separate raster slice for each unique time 't'\n",
    "out_grid = make_geocube(\n",
    "    vector_data=hero_fire,\n",
    "    resolution=(-500, 500),\n",
    "    measurements=[\"fireID\"],\n",
    "    output_crs=\"EPSG:9311\",\n",
    "    group_by=\"t\"\n",
    ")\n",
    "\n",
    "# Inspect the resulting xarray Dataset containing the rasterized fire data\n",
    "print(out_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b0d9b0",
   "metadata": {},
   "source": [
    "## Okay, now I've got a simple grid for a single fire.. time to get weather data for it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b77bd5",
   "metadata": {},
   "source": [
    "Get the apprpriate lat/long translated into degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c556a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Get the tight bounds of the fire (minx, miny, maxx, maxy)\n",
    "import xarray as xr\n",
    "ds = xr.open_zarr(\"https://data.dynamical.org/noaa/hrrr/forecast-48-hour/latest.zarr?email=optional@email.com\")\n",
    "\n",
    "\n",
    "minx, miny, maxx, maxy = hero_fire.total_bounds\n",
    "\n",
    "# 2. Convert these 4 numbers to Latitude/Longitude\n",
    "# I use the transformer from the dataframe's CRS to the standard Lat/Lon (EPSG:4326)\n",
    "import pyproj\n",
    "# 1. Setup the Transformer\n",
    "# FROM: EPSG:9311 ('hero_fire' meters)\n",
    "# TO:   ds.rio.crs (The HRRR model's meters)\n",
    "transformer = pyproj.Transformer.from_crs(\"EPSG:9311\", ds.rio.crs, always_xy=True)\n",
    "\n",
    "# Transform the corners\n",
    "x_start, y_start = transformer.transform(minx, miny)\n",
    "x_end, y_end = transformer.transform(maxx, maxy)\n",
    "\n",
    "print(\"--- Weather Request Box ---\")\n",
    "print(f\"West/East (x meters): {x_start:.2f} to {y_start:.2f}\")\n",
    "print(f\"South/North (y meters): {x_end:.2f} to {y_end:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a31091",
   "metadata": {},
   "source": [
    "Query for the weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4628d22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice the dataset\n",
    "# We select the 'x' range and 'y' range.\n",
    "# Note: We slice from Min to Max.\n",
    "my_subset = ds.sel(\n",
    "    x=slice(x_start, x_end),\n",
    "    y=slice(y_end,y_start)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96992c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the start and end dates directly from the row\n",
    "t_start = hero_fire['t_st'].values[0]\n",
    "t_end   = hero_fire['t_ed'].values[0]\n",
    "\n",
    "# Instead of a manual transformer, we just tell the fire:\n",
    "fire_hrrr = hero_fire.to_crs(ds.rio.crs)\n",
    "\n",
    "# Now extract the bounds from this new projected shape\n",
    "# .total_bounds returns (minx, miny, maxx, maxy)\n",
    "min_x, min_y, max_x, max_y = fire_hrrr.total_bounds\n",
    "\n",
    "subset = ds.sel(\n",
    "    x=slice(min_x, max_x),\n",
    "    y=slice(max_y, min_y), \n",
    "    init_time=slice(t_start, t_end)\n",
    ")\n",
    "\n",
    "print(f\"Time Range: {t_start} to {t_end}\")\n",
    "print(f\"X Range: {min_x:.2f} to {max_x:.2f}\")\n",
    "print(\"Subset Shape:\", subset.dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db1f306",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Draw a quick map\n",
    "frame_0 = subset['temperature_2m'].isel(init_time=0, lead_time=0)\n",
    "plt.figure(figsize=(10, 6))\n",
    "frame_0.plot()\n",
    "plt.title(f\"Temperature at Fire Start: {t_start}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c7ae1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean across the spatial dimensions (x and y)\n",
    "daily_weather = subset.mean(dim=['x', 'y'])\n",
    "\n",
    "print(\"New Shape:\", daily_weather['temperature_2m'].shape)\n",
    "\n",
    "# Now let's plot the timeline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# We plot the 'lead_time' (hours ahead) on the X-axis\n",
    "daily_weather['temperature_2m'].isel(init_time=0).plot()\n",
    "plt.title(\"Average Fire Temperature Over 48 Hours\")\n",
    "plt.xlabel(\"Hours Since Forecast Start\")\n",
    "plt.ylabel(\"Temperature (C)\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1b3ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import os\n",
    "import geopandas as gpd\n",
    "import rioxarray  # Required for .rio.crs\n",
    "from tqdm import tqdm # <--- Progress Bar Import\n",
    "from joblib import Parallel, delayed\n",
    "from shapely.ops import unary_union\n",
    "from collections import Counter\n",
    "\n",
    "# 1. SETUP\n",
    "output_dir = Path(\"..\") / \"data\" / \"training_data\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "dataset_start = pd.to_datetime(\"2018-07-15\")\n",
    "\n",
    "# 2. AGGREGATION: THE UNION METHOD\n",
    "print(f\"Original Row Count: {len(df_flat)}\")\n",
    "df_flat['t'] = pd.to_datetime(df_flat['t'])\n",
    "\n",
    "def combine_geoms(series):\n",
    "    return unary_union(series)\n",
    "\n",
    "print(\"Aggregating snapshots into unique Fire Events (Calculating Unions)...\")\n",
    "fire_events = df_flat.groupby('fireID').agg({\n",
    "    't': ['min', 'max'],\n",
    "    'hull': combine_geoms\n",
    "}).reset_index()\n",
    "\n",
    "fire_events.columns = ['fireID', 't_start', 't_end', 'geometry']\n",
    "\n",
    "# Filter Post-2018\n",
    "valid_fires = fire_events[fire_events['t_start'] >= dataset_start].copy()\n",
    "global_crs = df_flat.crs \n",
    "\n",
    "print(f\"Unique fires to download: {len(valid_fires)}\")\n",
    "\n",
    "\n",
    "# 3. CONNECT\n",
    "ds = xr.open_zarr(\n",
    "    \"https://data.dynamical.org/noaa/hrrr/forecast-48-hour/latest.zarr?email=optional@email.com\",\n",
    "    decode_coords=\"all\"\n",
    ")\n",
    "\n",
    "# 4. WORKER FUNCTION (With Smart Slicing)\n",
    "def process_fire(row, weather_ds, output_folder, input_crs):\n",
    "    try:\n",
    "        fire_id = int(row['fireID'])\n",
    "        t_start = row['t_start']\n",
    "        t_end   = row['t_end']\n",
    "        \n",
    "\n",
    "        # --- GEOMETRY TRANSFORMATION ---\n",
    "        fire_gs = gpd.GeoSeries([row['geometry']], crs=input_crs)\n",
    "        \n",
    "        # Check for CRS in weather data\n",
    "        if weather_ds.rio.crs is None:\n",
    "             return \"ERROR_NO_WEATHER_CRS\"\n",
    "             \n",
    "        fire_proj = fire_gs.to_crs(weather_ds.rio.crs)\n",
    "        min_x, min_y, max_x, max_y = fire_proj.total_bounds\n",
    "\n",
    "        # 1. Try Standard Slice (Bottom-Up)\n",
    "        subset = weather_ds.sel(\n",
    "            x=slice(min_x, max_x),\n",
    "            y=slice(min_y, max_y), \n",
    "            init_time=slice(t_start, t_end)\n",
    "        )\n",
    "        \n",
    "        # 2. If Empty, Try Inverted Slice (Top-Down)\n",
    "        # This handles grids where Y coordinates decrease from North to South\n",
    "        if subset.sizes['y'] == 0:\n",
    "             subset = weather_ds.sel(\n",
    "                x=slice(min_x, max_x),\n",
    "                y=slice(max_y, min_y), # <--- Swapped order\n",
    "                init_time=slice(t_start, t_end)\n",
    "            )\n",
    "\n",
    "        # 3. Validation\n",
    "        if subset.sizes['x'] == 0 or subset.sizes['y'] == 0:\n",
    "            return \"SKIPPED_OUT_OF_BOUNDS\"\n",
    "            \n",
    "        if subset.sizes['init_time'] == 0:\n",
    "            return \"SKIPPED_NO_TIME_MATCH\"\n",
    "\n",
    "        # F. Download and Save\n",
    "        subset.load()\n",
    "        \n",
    "        file_name = f\"fireID_{fire_id}_weather.nc\" \n",
    "        save_path = os.path.join(output_folder, file_name)\n",
    "        subset.to_netcdf(save_path)\n",
    "        \n",
    "        return \"SUCCESS\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"ERROR: {str(e)}\"\n",
    "\n",
    "# 5. EXECUTE\n",
    "print(f\"Starting parallel download...\")\n",
    "\n",
    "# tqdm progress bar \n",
    "results = Parallel(n_jobs=8, prefer=\"threads\")(\n",
    "    delayed(process_fire)(row, ds, output_dir, global_crs)\n",
    "    for index, row in tqdm(valid_fires.iterrows(), total=len(valid_fires))\n",
    ")\n",
    "\n",
    "# SUMMARY\n",
    "print(\"-\" * 30)\n",
    "counts = Counter(results)\n",
    "print(\"Detailed Results:\")\n",
    "for status, count in counts.items():\n",
    "    print(f\"{status}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198e54f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
